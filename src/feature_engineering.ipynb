{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering & Model Testing\n",
    "This notebook is used for model prototyping & experimentation of feature engineering techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from util.data_access import load_baseline_data\n",
    "from util.preprocess import get_preprocessed_data, train_test_split_by_step\n",
    "from util.tracking import (\n",
    "    get_classification_metrics,\n",
    "    HGBM_PARAMS,\n",
    "    get_experiment_id,\n",
    ")\n",
    "from util import columns\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noreorder\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from dotenv import load_dotenv\n",
    "import shap\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "mlflow.set_tracking_uri(os.environ[\"MLFLOW_TRACKING_URI\"])\n",
    "EXPERIMENT_NAME = \"Fraud Model Feature Engineering Loop\"\n",
    "EXPERIMENT_ID = get_experiment_id(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = load_baseline_data()\n",
    "\n",
    "df = get_preprocessed_data(df_raw)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split_by_step(\n",
    "    data=df, step=\"step\", target=\"fraud\", train_size=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(i in columns.NUMERICAL for i in columns.FRAUD_COMMITED_MEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH = False\n",
    "train_data = X_train.loc[:, columns.NUMERICAL]\n",
    "valid_data = X_valid.loc[:, columns.NUMERICAL]\n",
    "\n",
    "model = HistGradientBoostingClassifier(\n",
    "    **HGBM_PARAMS,\n",
    ")\n",
    "\n",
    "if SEARCH:\n",
    "    param_dist = {\n",
    "        \"min_samples_leaf\": (30, 80),\n",
    "        \"max_leaf_nodes\": (30, 80),\n",
    "        \"learning_rate\": (1e-3, 1e-0, \"log-uniform\"),\n",
    "        \"l2_regularization\": (50, 1000),\n",
    "        \"max_bins\": (40, 150),\n",
    "    }\n",
    "    estimator = BayesSearchCV(\n",
    "        model, search_spaces=param_dist, n_iter=50, cv=5, n_jobs=-1\n",
    "    )\n",
    "    estimator.fit(train_data, y_train)\n",
    "    params = estimator.best_params_\n",
    "else:\n",
    "    params = HGBM_PARAMS\n",
    "    estimator = model\n",
    "    estimator.fit(train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(experiment_id=EXPERIMENT_ID) as run:\n",
    "    mlflow.log_param(\"Train Data Dimension\", train_data.shape)\n",
    "    mlflow.log_param(\"Train Target Bad Rate\", y_train.mean())\n",
    "    mlflow.log_param(\"Valid Data Dimension\", valid_data.shape)\n",
    "    mlflow.log_param(\"Valid Target Dimension\", y_valid.mean())\n",
    "\n",
    "    mlflow.log_param(\"Model Type\", model.__class__.__name__)\n",
    "    y_pred_train = estimator.predict(train_data)\n",
    "    y_pred_proba_train = estimator.predict(train_data)\n",
    "    train_metrics = get_classification_metrics(\n",
    "        y_train, y_pred_train, y_pred_proba_train\n",
    "    )\n",
    "\n",
    "    for key, val in params.items():\n",
    "        mlflow.log_param(key, val)\n",
    "\n",
    "    for key, val in train_metrics.items():\n",
    "        mlflow.log_metric(f\"Train {key}\", val)\n",
    "\n",
    "    y_pred_valid = estimator.predict(valid_data)\n",
    "    y_pred_proba_valid = estimator.predict(valid_data)\n",
    "    train_metrics = get_classification_metrics(\n",
    "        y_valid, y_pred_valid, y_pred_proba_valid\n",
    "    )\n",
    "\n",
    "    for key, val in train_metrics.items():\n",
    "        mlflow.log_metric(f\"Validation {key}\", val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "explainer = shap.TreeExplainer(estimator)\n",
    "explain_data = train_data.sample(frac=0.1)\n",
    "shap_values = explainer.shap_values(explain_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, explain_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "246045aacf2e17d755aa090c4afeac54f892a9c5f9e3d8c8bd024131ea4861d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
